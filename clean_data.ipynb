{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pyreadr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/j8d1_lqx5wz_zztjb28h8rkh0000gn/T/ipykernel_92140/571683533.py:1: DtypeWarning: Columns (45,46,47,51,52,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('voter_file.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      voterbase_id  version                 household_id_hash  \\\n",
      "0  MO-000000000015  2024_01  666dd978701b0ad828eb3c35262548ad   \n",
      "1  MO-000000000025  2024_01  cb646c5b6581ea80498fa4a0525e46cd   \n",
      "2  MO-000000000051  2024_01  ec0fe42f45bac7bb43d2ce89765c417c   \n",
      "3  MO-000000000083  2024_01  05f243ec7fd107768c583374c8076745   \n",
      "4  MO-000000000085  2024_01  f046eb6de85a25572c7ba029e14364a4   \n",
      "\n",
      "  tsmart_exact_track_id  smartvan_id tsmart_precinct_id    sos_id  \\\n",
      "0       Y29454846321647          8.0                008  42017891   \n",
      "1       Y29454238536941         17.0                517  46591254   \n",
      "2       Y29454813432049         36.0            FLO.006  73280446   \n",
      "3       Y29458488718403         58.0                105  46604287   \n",
      "4       Y29454689393585         60.0                 15  20444309   \n",
      "\n",
      "   legal_commercial_model_usage_ok  vb_deceased  vote_g2024  ...  \\\n",
      "0                                0            0           0  ...   \n",
      "1                                1            0           0  ...   \n",
      "2                                1            0           0  ...   \n",
      "3                                1            0           0  ...   \n",
      "4                                1            0           0  ...   \n",
      "\n",
      "   acs_pct_educ_bachelors_bucket  household_income_bucket  home_value_bucket  \\\n",
      "0                     Low (<25%)                $30k-$49k    Less than $100k   \n",
      "1                Middle (25-50%)              $100k-$149k        $150k-$199k   \n",
      "2                     Low (<25%)              $100k-$149k    Less than $100k   \n",
      "3                Middle (25-50%)                $30k-$49k        $200k-$249k   \n",
      "4                     Low (<25%)                $30k-$49k        $100k-$149k   \n",
      "\n",
      "   household_net_worth_bucket  is_dupe   voterbase_id.1  turnout_score  \\\n",
      "0                     $0-$25k        0  MO-000000000015       0.694679   \n",
      "1                 $150k-$249k        0  MO-000000000025       0.970724   \n",
      "2                     $0-$25k        0  MO-000000000051       0.482408   \n",
      "3                 $250k-$749k        0  MO-000000000083       0.732388   \n",
      "4                   $25k-$74k        0  MO-000000000085       0.781242   \n",
      "\n",
      "   support_score  synthetic_persuasion_score  gotv_score  \n",
      "0       0.626076                    0.015162    0.001436  \n",
      "1       0.561578                    0.022350    0.000093  \n",
      "2       0.901789                    0.003933    0.005420  \n",
      "3       0.710358                    0.013994    0.002212  \n",
      "4       0.604653                    0.017429    0.000958  \n",
      "\n",
      "[5 rows x 124 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('voter_file.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     61\n",
      "int64      34\n",
      "float64    29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # Turn object columns into strings for easier processing\n",
    "# object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# def convert_to_string(value):\n",
    "#     return str(value)\n",
    "\n",
    "# # Apply the conversion function only to mixed columns using applymap\n",
    "# df[object_columns] = df[object_columns].map(convert_to_string)\n",
    "\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     61\n",
      "int64      34\n",
      "float64    29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def convert_to_string_column(col):\n",
    "#     return col.apply(str)\n",
    "\n",
    "# # Apply the conversion function only to mixed columns using apply\n",
    "# df[object_columns] = df[object_columns].apply(lambda col: convert_to_string_column(col))\n",
    "\n",
    "# print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4258869, 124)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "\n",
    "# Delete irrelevant columns\n",
    "del df['voterbase_id'], df['version'], df['household_id_hash'], df['tsmart_exact_track_id'], df['smartvan_id'], df['tsmart_precinct_id'], df['sos_id'], df['tsmart_census_block_fips_2010'], df['tsmart_cd_version_2020'], df['tsmart_cd_2020'], df['tsmart_cd_version_2010'], df['tsmart_sd'], df['tsmart_sd_2010']\n",
    "del df['tsmart_sd_version'], df['tsmart_sd_version_2010'], df['tsmart_hd_version'], df['tsmart_hd_version_2020'], df['tsmart_hd_version_2010'], df['vf_reg_cd_version'], df['vf_reg_cd_version_2010'], df['vf_reg_sd_2010'], df['vf_reg_sd_version'], df['vf_reg_sd_version_2020'], df['vf_reg_sd_version_2010'], df['vf_reg_hd'], df['vf_reg_hd_2010']\n",
    "del df['vf_reg_hd_version_2010'], df['vf_reg_census_id'], df['vf_reg_census_id_2010'], df['vf_reg_census_id_version'], df['vf_reg_census_id_version_2010'], df['vf_reg_precinct_name'], df['vf_reg_place_name'], df['vb_dob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0065201295528617 -0.0058101947090944\n",
      "0.97184016271401 0.0747956319413997\n",
      "0.9909344186186488 0.0313679301143077\n",
      "0.0227886075320771 0.0004339507877027\n"
     ]
    }
   ],
   "source": [
    "print(max(df['gotv_score']) , min(df['gotv_score']))\n",
    "print(max(df['turnout_score']) , min(df['turnout_score']))\n",
    "print(max(df['support_score']) , min(df['support_score']))\n",
    "print(max(df['synthetic_persuasion_score']) , min(df['synthetic_persuasion_score']))\n",
    "\n",
    "df['gotv_score'] = (df['gotv_score'] - np.min(df['gotv_score'])) / (np.max(df['gotv_score']) - np.min(df['gotv_score']))\n",
    "df['synthetic_persuasion_score'] = (df['synthetic_persuasion_score'] - np.min(df['synthetic_persuasion_score'])) / (np.max(df['synthetic_persuasion_score']) - np.min(df['synthetic_persuasion_score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4258869, 90)\n",
      "1.0 0.0\n",
      "0.97184016271401 0.0747956319413997\n",
      "0.9909344186186488 0.0313679301143077\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(max(df['gotv_score']) , min(df['gotv_score']))\n",
    "print(max(df['turnout_score']) , min(df['turnout_score']))\n",
    "print(max(df['support_score']) , min(df['support_score']))\n",
    "print(max(df['synthetic_persuasion_score']) , min(df['synthetic_persuasion_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_scores(value):\n",
    "    if value <= .10:\n",
    "        return 0\n",
    "    elif value <= .20:\n",
    "        return 1\n",
    "    elif value <= .30:\n",
    "        return 2\n",
    "    elif value <= .36:\n",
    "        return 3\n",
    "    elif value <= .41:\n",
    "        return 4\n",
    "    elif value <= .45:\n",
    "        return 5\n",
    "    elif value <= .47:\n",
    "        return 6\n",
    "    elif value <= .49:\n",
    "        return 7\n",
    "    elif value <= .51:\n",
    "        return 8\n",
    "    elif value <= .53:\n",
    "        return 9\n",
    "    elif value <= .55:\n",
    "        return 10\n",
    "    elif value <= .59:\n",
    "        return 11\n",
    "    elif value <= .64:\n",
    "        return 12\n",
    "    elif value <= .70:\n",
    "        return 13\n",
    "    elif value <= .75:\n",
    "        return 14\n",
    "    elif value <= .80:\n",
    "        return 15\n",
    "    elif value <= .90:\n",
    "        return 16\n",
    "    elif value <= 1.00:\n",
    "        return 17\n",
    "    else: pass\n",
    "\n",
    "df['gotv_score'] = df['gotv_score'].apply(map_scores)\n",
    "df['turnout_score'] = df['turnout_score'].apply(map_scores)\n",
    "df['support_score'] = df['support_score'].apply(map_scores)\n",
    "df['synthetic_persuasion_score'] = df['synthetic_persuasion_score'].apply(map_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Factorize the entire dataset\n",
    "### Include NaNs as factor levels\n",
    "\n",
    "# Identify columns with NaNs\n",
    "columns_with_missing = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "# Convert columns to factor variables\n",
    "for col in df.columns:\n",
    "    if col not in columns_with_missing:\n",
    "        df[col] = pd.factorize(df[col])[0]  # Factorize non-missing values\n",
    "\n",
    "# Handle missing values\n",
    "for col in columns_with_missing:\n",
    "    df[col] = pd.factorize(df[col].fillna('MISSING'))[0]  # Factorize with 'MISSING' as a category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64    90\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create the 'out' or 'target' dataset\n",
    "\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# df.to_csv('cleaned.csv', index=False)\n",
    "\n",
    "# out = df[[\"vote_g2022\", \"vote_p2022\"]]\n",
    "# filt = df.drop(columns = [\"vote_g2022\", \"vote_p2022\", 'vote_g2023', 'vote_g2024'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of values for feature legal_commercial_model_usage_ok :2 -- [0 1]\n",
      "The number of values for feature vote_g2020 :2 -- [0 1]\n",
      "The number of values for feature vote_g2018 :2 -- [0 1]\n",
      "The number of values for feature vote_g2016 :2 -- [0 1]\n",
      "The number of values for feature vote_g2014 :2 -- [0 1]\n",
      "The number of values for feature vote_g2012 :2 -- [0 1]\n",
      "The number of values for feature vote_p2018 :2 -- [0 1]\n",
      "The number of values for feature vote_any_primary_since_2012 :2 -- [0 1]\n",
      "The number of values for feature firsttimeseen_voterid:76\n",
      "The number of values for feature state_code:58\n",
      "The number of values for feature tsmart_county_fips:2691\n",
      "The number of values for feature tsmart_census_id_version :2 -- [0 1]\n",
      "The number of values for feature tsmart_census_id_version_2010 :2 -- [0 1]\n",
      "The number of values for feature housing_temp_address :2 -- [0 1]\n",
      "The number of values for feature tsmart_county_name:1606\n",
      "The number of values for feature tsmart_dma_id:211\n",
      "The number of values for feature tsmart_dma_name:211\n",
      "The number of values for feature tsmart_cd:53\n",
      "The number of values for feature tsmart_cd_2010:54\n",
      "The number of values for feature tsmart_cd_version :2 -- [0 1]\n",
      "The number of values for feature tsmart_sd_2020:237\n",
      "The number of values for feature tsmart_sd_version_2020:50\n",
      "The number of values for feature tsmart_hd:806\n",
      "The number of values for feature tsmart_hd_2020:949\n",
      "The number of values for feature tsmart_hd_2010:921\n",
      "The number of values for feature tsmart_place_name:8182\n",
      "The number of values for feature vf_reg_county_fips:115\n",
      "The number of values for feature vf_reg_county_name:116\n",
      "The number of values for feature vf_reg_dma:15\n",
      "The number of values for feature vf_reg_dma_name:15\n",
      "The number of values for feature vf_reg_cd :9 -- [0 1 2 3 4 5 6 7 8]\n",
      "The number of values for feature vf_reg_cd_2020 :9 -- [0 1 2 3 4 5 6 7 8]\n",
      "The number of values for feature vf_reg_cd_2010 :9 -- [0 1 2 3 4 5 6 7 8]\n",
      "The number of values for feature vf_reg_cd_version_2020 :2 -- [0 1]\n",
      "The number of values for feature vf_reg_sd:35\n",
      "The number of values for feature vf_reg_sd_2020:35\n",
      "The number of values for feature vf_reg_hd_2020:164\n",
      "The number of values for feature vf_reg_hd_version :2 -- [0 1]\n",
      "The number of values for feature vf_reg_hd_version_2020 :2 -- [0 1]\n",
      "The number of values for feature vf_reg_precinct_id:1759\n",
      "The number of values for feature vf_reg_zip:1057\n",
      "The number of values for feature vb_email_append_ind :2 -- [0 1]\n",
      "The number of values for feature vb_email_append_hh :2 -- [0 1]\n",
      "The number of values for feature has_phone :2 -- [0 1]\n",
      "The number of values for feature has_wirelessphone :2 -- [0 1]\n",
      "The number of values for feature has_email :2 -- [0 1]\n",
      "The number of values for feature vb_mailable :2 -- [0 1]\n",
      "The number of values for feature coalesced_noncommercial_age:87\n",
      "The number of values for feature coalesced_noncommercial_age_is_modeled :2 -- [0 1]\n",
      "The number of values for feature coalesced_noncommercial_age_source :4 -- [0 1 2 3]\n",
      "The number of values for feature age_bucket_noncommercial :4 -- [0 1 2 3]\n",
      "The number of values for feature race5way_noncommercial :5 -- [0 1 2 3 4]\n",
      "The number of values for feature subethnicity_noncommercial:21\n",
      "The number of values for feature gender_noncommercial :2 -- [0 1]\n",
      "The number of values for feature marriage_noncommercial :2 -- [0 1]\n",
      "The number of values for feature parent_noncommercial :2 -- [0 1]\n",
      "The number of values for feature religion_noncommercial:10\n",
      "The number of values for feature gender_score_is_modeled_noncommercial :2 -- [0 1]\n",
      "The number of values for feature ts_homeowner :2 -- [0 1]\n",
      "The number of values for feature household_income_is_null :2 -- [0 1]\n",
      "The number of values for feature home_value_is_null :2 -- [0 1]\n",
      "The number of values for feature household_net_worth_is_null :2 -- [0 1]\n",
      "The number of values for feature urbanicity :3 -- [0 1 2]\n",
      "The number of values for feature acs_median_hh_income_bucket :3 -- [0 1 2]\n",
      "The number of values for feature acs_pct_educ_bachelors_bucket :3 -- [0 1 2]\n",
      "The number of values for feature household_income_bucket :6 -- [0 1 2 3 4 5]\n",
      "The number of values for feature home_value_bucket :7 -- [0 1 2 3 4 5 6]\n",
      "The number of values for feature household_net_worth_bucket :7 -- [0 1 2 3 4 5 6]\n",
      "The number of values for feature is_dupe :2 -- [0 1]\n",
      "The number of values for feature turnout_score:19\n",
      "The number of values for feature support_score:19\n",
      "The number of values for feature synthetic_persuasion_score:19\n",
      "The number of values for feature gotv_score:19\n",
      "(4258869, 73)\n"
     ]
    }
   ],
   "source": [
    "# filt.isnull().sum()\n",
    "# out.isnull().sum()\n",
    "\n",
    "# # Turn columns of filt into integers if they are float\n",
    "# # for col in filt.columns:\n",
    "# #     filt.loc[:, col] = filt[col].astype('Int64')\n",
    "\n",
    "# # for col in out.columns:\n",
    "# #     out.loc[:, col] = out[col].astype('Int64')\n",
    "\n",
    "# # Print the number of unique items in each column to get a sense of \"vocabulary\" size\n",
    "# for column in filt:\n",
    "#     try: \n",
    "#         unique_vals = np.unique(df[column])\n",
    "#     except:\n",
    "#         unique_vals = df[column].unique()\n",
    "\n",
    "#     nr_vals = len(unique_vals)\n",
    "\n",
    "#     if nr_vals == 1:\n",
    "#         del filt[column]\n",
    "#     elif nr_vals < 10:\n",
    "#         print('The number of values for feature {} :{} -- {}'.format(column, nr_vals, unique_vals))\n",
    "#     elif nr_vals > 10000:\n",
    "#         del filt[column]\n",
    "#     else:\n",
    "#         print('The number of values for feature {}:{}'.format(column, nr_vals))\n",
    "\n",
    "# print(filt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# columns_with_null = filt.columns[filt.isnull().any()].tolist()\n",
    "# print(columns_with_null)\n",
    "# filt[columns_with_null] = filt[columns_with_null].fillna('none')\n",
    "\n",
    "# columns_with_null = out.columns[out.isnull().any()].tolist()\n",
    "# if columns_with_null:\n",
    "#     out[columns_with_null] = out[columns_with_null].fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  legal_commercial_model_usage_ok vb_deceased vote_g2024 vote_g2023  \\\n",
      "0                             aa0         ab0        ac0        ad0   \n",
      "1                             aa1         ab0        ac0        ad0   \n",
      "2                             aa1         ab0        ac0        ad0   \n",
      "3                             aa1         ab0        ac0        ad0   \n",
      "4                             aa1         ab0        ac0        ad0   \n",
      "\n",
      "  vote_g2022 vote_g2021 vote_g2020 vote_g2019 vote_g2018 vote_g2016  ...  \\\n",
      "0        ae0        af0        ag0        ah0        ai0        aj0  ...   \n",
      "1        ae1        af0        ag0        ah0        ai0        aj1  ...   \n",
      "2        ae0        af0        ag0        ah0        ai1        aj0  ...   \n",
      "3        ae0        af0        ag0        ah0        ai0        aj1  ...   \n",
      "4        ae0        af0        ag0        ah0        ai0        aj1  ...   \n",
      "\n",
      "  acs_pct_educ_bachelors_bucket household_income_bucket home_value_bucket  \\\n",
      "0                           dc0                     dd0               de0   \n",
      "1                           dc1                     dd1               de1   \n",
      "2                           dc0                     dd1               de0   \n",
      "3                           dc1                     dd0               de2   \n",
      "4                           dc0                     dd0               de3   \n",
      "\n",
      "  household_net_worth_bucket is_dupe voterbase_id.1 turnout_score  \\\n",
      "0                        df0     dg0            dh0           di0   \n",
      "1                        df1     dg0            dh1           di1   \n",
      "2                        df0     dg0            dh2           di2   \n",
      "3                        df2     dg0            dh3           di3   \n",
      "4                        df3     dg0            dh4           di4   \n",
      "\n",
      "  support_score synthetic_persuasion_score gotv_score  \n",
      "0           dj0                        dk0        dl0  \n",
      "1           dj1                        dk1        dl1  \n",
      "2           dj2                        dk2        dl2  \n",
      "3           dj3                        dk3        dl3  \n",
      "4           dj0                        dk4        dl4  \n",
      "\n",
      "[5 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "def generate_double_strings():\n",
    "    double_strings = []\n",
    "    for char1 in string.ascii_lowercase:\n",
    "        for char2 in string.ascii_lowercase:\n",
    "            double_strings.append(char1 + char2)\n",
    "    return double_strings\n",
    "\n",
    "column_mapping_filt = dict(zip(df.columns, generate_double_strings()))\n",
    "# column_mapping_out = dict(zip(out.columns, generate_double_strings()))\n",
    "\n",
    "# Define the function to append double strings to values\n",
    "def append_double_string(val, col_name, column_mapping):\n",
    "    if pd.notna(val):\n",
    "        return f\"{column_mapping[col_name]}{val}\"\n",
    "    else:\n",
    "        return val  # Return NaN if the value is NaN\n",
    "\n",
    "# Apply the function element-wise to the DataFrame\n",
    "for col in df.columns:\n",
    "    df.loc[:, col] = df[col].apply(lambda x, col_name=col: append_double_string(x, col_name, column_mapping_filt))\n",
    "\n",
    "# for col in out.columns:\n",
    "#     out.loc[:, col] = out[col].apply(lambda x, col_name=col: append_double_string(x, col_name, column_mapping_out))\n",
    "\n",
    "# Convert all values in the DataFrame to strings\n",
    "# filt = filt.astype(str)\n",
    "# filt = filt.replace(\"<NA>\", pd.NA)\n",
    "\n",
    "# out = out.astype(str)\n",
    "# out = out.replace(\"<NA>\", pd.NA)\n",
    "\n",
    "print(df.head())\n",
    "# print(out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filt.to_csv('filtered_data.csv', index=False)\n",
    "# out.to_csv('targets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactorized_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('factorized_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littleguy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
